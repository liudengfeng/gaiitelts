import base64
import io
import logging
import mimetypes
import os
import re
import tempfile
import time
from datetime import timedelta
from functools import partial
from pathlib import Path

import numpy as np
import streamlit as st
from langchain.callbacks import StreamlitCallbackHandler
from langchain.chains import ConversationChain, LLMMathChain
from langchain.memory import ChatMessageHistory, ConversationBufferMemory
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
)
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_experimental.llm_symbolic_math.base import LLMSymbolicMathChain
from langchain_google_vertexai import (
    ChatVertexAI,
    HarmBlockThreshold,
    HarmCategory,
    VertexAI,
)
from moviepy.editor import VideoFileClip
from PIL import Image as PIL_Image
from PIL import ImageChops, ImageDraw, ImageOps
from vertexai.preview.generative_models import Content, GenerationConfig, Image, Part

from menu import menu
from gailib.google_ai import (
    display_generated_content_and_update_token,
    load_vertex_model,
    parse_generated_content_and_update_token,
    parse_json_string,
)

# from mypylib.math import remove_text_keep_illustrations
from gailib.math_pix import mathpix_ocr_read
from gailib.st_helper import (
    add_exercises_to_db,
    check_access,
    configure_google_apis,
    setup_logger,
    update_sidebar_status,
)
from gailib.st_setting import general_config

logger = logging.getLogger("streamlit")
setup_logger(logger)

CURRENT_CWD: Path = Path(__file__).parent.parent
IMAGE_DIR: Path = CURRENT_CWD / "resource/multimodal"

st.set_page_config(
    page_title="æ•°å­¦ä½œä¸šå¸®æ‰‹",
    page_icon=":abacus:",
    layout="wide",
)
menu()
check_access(False)
configure_google_apis()
add_exercises_to_db()
general_config(True)


# region ä¼šè¯çŠ¶æ€
# if "TESSDATA_PREFIX" not in os.environ:
#     os.environ["TESSDATA_PREFIX"] = str(CURRENT_CWD / "tessdata")


if "math-question" not in st.session_state:
    st.session_state["math-question"] = ""

if "math-illustration" not in st.session_state:
    st.session_state["math-illustration"] = None

if "math-question-prompt" not in st.session_state:
    st.session_state["math-question-prompt"] = ""

if "math-assistant-response" not in st.session_state:
    st.session_state["math-assistant-response"] = ""


def initialize_writing_chat():
    model_name = "gemini-pro"
    model = load_vertex_model(model_name)
    history = [
        Content(
            role="user",
            parts=[
                Part.from_text(
                    """ä½œä¸ºä¸€ä¸ªç²¾é€š Markdown æ•°å­¦å…¬å¼è¯­æ³•ï¼ˆä½¿ç”¨LaTeXï¼‰çš„AIï¼Œä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·çš„è¯·æ±‚ï¼Œæä¾›æ­£ç¡®çš„æ•°å­¦å˜é‡æˆ–è¡¨è¾¾å¼çš„Markdownä»£ç ã€‚å¦‚æœç”¨æˆ·æå‡ºä¸æ­¤æ— å…³çš„é—®é¢˜ï¼Œä½ éœ€è¦å©‰è½¬åœ°å¼•å¯¼ä»–ä»¬å›åˆ°ä¸»é¢˜ã€‚"""
                )
            ],
        ),
        Content(role="model", parts=[Part.from_text("Alright, let's proceed.")]),
    ]
    st.session_state["AI-Formula-Assistant"] = model.start_chat(history=history)


# endregion

# region æç¤ºè¯

CORRECTION_PROMPT_TEMPLATE = """
**ç°åœ¨å·²ç»æ›´æ–°äº†é¢˜ç›®ï¼Œä½ åªéœ€è¦å‚è€ƒå›¾ä¸­çš„ç¤ºæ„å›¾æˆ–æ’å›¾ã€‚**
ä¿®è®¢åçš„é¢˜ç›®ï¼š
...åœ¨æ­¤å¤„è¾“å…¥ä¿®è®¢åçš„é¢˜ç›®...
"""

EXAMPLES = r"""
- å¯¹äºè¡Œå†…çš„å˜é‡ä»£ç ï¼Œä½¿ç”¨ï¼š$x$
- å¯¹äºè¡Œå†…çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œä½¿ç”¨ `$x = y + z$`
- å¯¹äºæ•°å­¦å…¬å¼å—ï¼Œä½¿ç”¨ï¼š
$$
\begin{cases}
x + y = 10 \\
2x - y = 3
\end{cases}
$$
"""

# EXTRACT_TEST_QUESTION_PROMPT = f"""
# æ ¹æ®ä»¥ä¸‹è¦æ±‚ï¼Œä»å›¾ç‰‡ä¸­æå–æ•°å­¦é—®é¢˜çš„æ–‡æœ¬ï¼š
# - åªæå–è¯•é¢˜çš„æ–‡æœ¬å†…å®¹ï¼Œä¸åŒ…æ‹¬æ’å›¾æˆ–é™„æ³¨ã€‚
# - æ•°å­¦å…¬å¼ä½¿ç”¨ LaTeX è¯­æ³•ã€‚
# - æ‰€æœ‰çš„æ•°å­¦å˜é‡ã€è¡¨è¾¾å¼å’Œæ•°å­¦å…¬å¼éƒ½éœ€è¦åˆç†ä½¿ç”¨ `$` æˆ– `$$` è¿›è¡Œæ ‡æ³¨ã€‚
# - å¦‚æœè¯•é¢˜ä¸­çš„å†…å®¹ä»¥è¡¨æ ¼å½¢å¼å‘ˆç°ï¼Œåº”ä½¿ç”¨ Markdown ä¸­çš„ HTML è¡¨æ ¼è¯­æ³•è¿›è¡Œç¼–å†™ã€‚
# - é¡¹ç›®åˆ—è¡¨åº”ä½¿ç”¨æ ‡å‡†çš„ Markdown æ ¼å¼è¿›è¡Œç¼–å†™ã€‚
# - è¾“å‡º Markdown ä»£ç ã€‚
# - åªéœ€è¦æå–æ•°å­¦é—®é¢˜çš„æ–‡æœ¬ï¼Œæ— éœ€æä¾›è§£é¢˜ç­–ç•¥å’Œå…·ä½“ç­”æ¡ˆã€‚

# Markdownæ•°å­¦å˜é‡ã€è¡¨è¾¾å¼ã€å…¬å¼æ ¼å¼ç¤ºä¾‹ï¼š

# {EXAMPLES}
# """

EXTRACT_TEST_QUESTION_PROMPT = """\
ä»ä¸‹å›¾ä¸­æå–æ•°å­¦è¯•é¢˜æ–‡æœ¬ã€‚ä¸å¾—æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡å­—æˆ–è§£é‡Šã€‚

ä½ å¯å‚è€ƒå·²ç»æå–çš„æ–‡æœ¬ï¼Œå¦‚æœå‘ç°é”™è¯¯ï¼Œè¯·ä¿®æ­£ã€‚
æå–çš„æ–‡æœ¬ï¼š
{question}

Markdownæ•°å­¦å˜é‡ã€è¡¨è¾¾å¼ã€å…¬å¼æ ¼å¼ç¤ºä¾‹ï¼š
{exmples}
"""


SOLUTION_THOUGHT_PROMPT = """ä½ ç²¾é€šæ•°å­¦ï¼Œä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä»¥ä¸‹è¦æ±‚ï¼Œä¸ºå›¾ç‰‡ä¸­çš„æ•°å­¦é—®é¢˜æä¾›è§£é¢˜æ€è·¯ï¼š
1. ä½ çš„å—ä¼—æ˜¯ä¸­å›½{grade}å­¦ç”Ÿï¼Œä½ éœ€è¦æä¾›ä¸ä»–ä»¬èƒ½åŠ›åŒ¹é…çš„è§£é¢˜æ–¹æ³•ã€‚
2. å¦‚æœé—®é¢˜çš„éš¾åº¦æˆ–å†…å®¹ä¸æŒ‡å®šå¹´çº§çš„æ•™å­¦å¤§çº²ä¸ç¬¦ï¼Œä½ éœ€è¦ä»¥å°Šé‡å’Œç†è§£çš„æ€åº¦ï¼Œç¤¼è²Œåœ°å‘ç”¨æˆ·æŒ‡å‡ºè¿™ä¸€ç‚¹ã€‚
3. è¿™æ˜¯ä¸€é“{question_type}é¢˜ï¼Œä½ éœ€è¦æŒ‰ç…§é¢˜å‹çš„æ ‡å‡†èŒƒå¼è¿›è¡Œè§£ç­”ã€‚
4. ç®€è¦é˜è¿°è§£å†³é—®é¢˜çš„æ­¥éª¤å’Œæ‰€é‡‡ç”¨çš„æ–¹æ³•ï¼Œåˆ—å‡ºå¿…è¦çš„æ•°å­¦å…¬å¼å’Œè®¡ç®—æµç¨‹ï¼Œä½†æ— éœ€è¿›è¡Œè¯¦ç»†çš„æ•°å€¼è¿ç®—ã€‚
5. ä½¿ç”¨`$`æˆ–`$$`æ¥æ­£ç¡®æ ‡è¯†è¡Œå†…æˆ–å—çº§çš„æ•°å­¦å˜é‡å’Œå…¬å¼ã€‚

ä½ åªéœ€è¦å‚è€ƒå›¾ç‰‡ä¸­çš„æ’å›¾ï¼Œè¯•é¢˜æ–‡æœ¬å¦‚ä¸‹ï¼š
{question}


Markdownæ•°å­¦å˜é‡ã€è¡¨è¾¾å¼ã€å…¬å¼æ ¼å¼ç¤ºä¾‹ï¼š
{exmples}

**ä½ ä¸èƒ½æä¾›å…·ä½“çš„ç­”æ¡ˆã€‚**
"""

ANSWER_MATH_QUESTION_PROMPT = """ä½ ç²¾é€šæ•°å­¦ï¼Œä½ çš„ä»»åŠ¡æ˜¯æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ï¼Œåˆ†æ­¥è§£ç­”å›¾ä¸­çš„æ•°å­¦é¢˜ï¼š
1. è¿™æ˜¯ä¸€é“{question_type}é¢˜ï¼Œä½ éœ€è¦æŒ‰ç…§é¢˜å‹çš„æ ‡å‡†èŒƒå¼è¿›è¡Œè§£ç­”ã€‚
2. æ‚¨çš„å—ä¼—æ˜¯ä¸­å›½{grade}å­¦ç”Ÿï¼Œéœ€è¦æä¾›ä¸å…¶å­¦ä¹ é˜¶æ®µç›¸åŒ¹é…çš„è§£é¢˜æ–¹æ³•ã€‚
3. ä½¿ç”¨`$`æˆ–`$$`æ¥æ­£ç¡®æ ‡è¯†è¡Œå†…æˆ–å—çº§æ•°å­¦å˜é‡åŠå…¬å¼ã€‚

ä½ åªéœ€è¦å‚è€ƒå›¾ç‰‡ä¸­çš„æ’å›¾ï¼Œè¯•é¢˜æ–‡æœ¬å¦‚ä¸‹ï¼š
{question}

Markdownæ•°å­¦å˜é‡ã€è¡¨è¾¾å¼ã€å…¬å¼æ ¼å¼ç¤ºä¾‹ï¼š
{exmples}
"""


# endregion


# region å‡½æ•°
def reset_text_value(key, value=""):
    st.session_state[key] = value


def _process_media(uploaded_file):
    # ç”¨æ–‡ä»¶æ‰©å±•åç§°å½¢æˆ MIME ç±»å‹
    mime_type = mimetypes.guess_type(uploaded_file.name)[0]
    p = Part.from_data(data=uploaded_file.getvalue(), mime_type=mime_type)  # type: ignore

    duration = None
    if mime_type.startswith("video"):
        with tempfile.NamedTemporaryFile(suffix=".mp4") as temp_video_file:
            temp_video_file.write(uploaded_file.getvalue())
            temp_video_file.flush()
            clip = VideoFileClip(temp_video_file.name)
            duration = clip.duration  # è·å–è§†é¢‘æ—¶é•¿ï¼Œå•ä½ä¸ºç§’

    return {"mime_type": mime_type, "part": p, "duration": duration}


@st.cache_data(ttl=timedelta(hours=1))
def create_temp_file_from_upload(uploaded_file):
    # è·å–å›¾ç‰‡æ•°æ®
    image_bytes = uploaded_file.getvalue()

    # è·å–æ–‡ä»¶çš„ MIME ç±»å‹
    mime_type = uploaded_file.type

    # æ ¹æ® MIME ç±»å‹è·å–æ–‡ä»¶æ‰©å±•å
    ext = mimetypes.guess_extension(mime_type)

    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ï¼Œä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶æ‰©å±•å
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=ext)

    # å°†å›¾ç‰‡æ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶
    temp_file.write(image_bytes)
    temp_file.close()

    # è¿”å›ä¸´æ—¶æ–‡ä»¶çš„è·¯å¾„
    return temp_file.name


@st.cache_data(ttl=timedelta(hours=1))
def image_to_dict(uploaded_file):
    # è¿”å›ä¸´æ—¶æ–‡ä»¶çš„è·¯å¾„
    image_message = {
        "type": "image_url",
        "image_url": {"url": create_temp_file_from_upload(uploaded_file)},
    }
    # logger.info(f"url: {temp_file.name}")
    return image_message


# @st.cache_data(ttl=timedelta(hours=1))
# def image_to_dict(uploaded_file):
#     # è·å–å›¾ç‰‡æ•°æ®
#     image_bytes = uploaded_file.getvalue()

#     # è¿”å›ä¸´æ—¶æ–‡ä»¶çš„è·¯å¾„
#     image_message = {
#         "type": "image_url",
#         "image_url": {
#             "url": f"data:image/jpeg;base64,{base64.b64encode(image_bytes).decode('utf-8')}"
#         },
#     }
#     return image_message

ANALYZE_IMAGE_COORDINATES_TEMPLATE = """
ç»“åˆå·²ç»æå–çš„æ–‡æœ¬å’Œä»¥ä¸‹ä¸¤å¹…å›¾åƒï¼ŒæŒ‡å‡ºæ’å›¾çš„ box åæ ‡ã€‚
æ–¹æ³•ä»‹ç»ï¼š
- ä»åŸå›¾ä¸­é®æ©å·²ç»æå–çš„æ–‡æœ¬éƒ¨åˆ†ã€‚
- å‚è€ƒåˆ†ç¦»çš„å›¾ç‰‡ï¼Œåˆ†ç¦»çš„å›¾ç‰‡åŒ…å«äº†æ’å›¾ï¼Œä½†å¯èƒ½é”™è¯¯ä¿ç•™äº†æ–‡æœ¬ã€‚
- ç»“åˆä¸¤å¹…å›¾åƒï¼ŒæŒ‡å‡ºæ’å›¾çš„ box åæ ‡ï¼Œå­—å…¸åˆ—è¡¨ä»¥JSONæ ¼å¼è¾“å‡ºã€‚


åŸå›¾ï¼š
{original}

æå–çš„æ–‡æœ¬ï¼š
{text}

åˆ†ç¦»çš„å›¾ç‰‡ï¼š
{image}

è¾“å‡ºç¤ºä¾‹ï¼š
```json
[
    {
        "x": 0,
        "y": 0,
        "width": 100,
        "height": 100
    },
]
```       
"""


def analyze_coordinates_prompt(
    original_image_path, separated_image_path, extracted_text
):
    contents_info = []
    prompt = """
ç»“åˆå·²ç»æå–çš„æ–‡æœ¬å’Œä»¥ä¸‹ä¸¤å¹…å›¾åƒï¼ŒæŒ‡å‡ºæ’å›¾åœ¨åŸå›¾ä¸­çš„ box åæ ‡ã€‚
æ–¹æ³•ä»‹ç»ï¼š
- ä»åŸå›¾ä¸­é®æ©å·²ç»æå–çš„æ–‡æœ¬éƒ¨åˆ†ã€‚
- å‚è€ƒåˆ†ç¦»çš„å›¾ç‰‡ï¼Œåˆ†ç¦»çš„å›¾ç‰‡åŒ…å«äº†æ’å›¾ï¼Œä½†å¯èƒ½é”™è¯¯åœ°ä¿ç•™æˆ–è€…åˆ é™¤äº†æ–‡æœ¬ã€‚
- ç»“åˆä¸¤å¹…å›¾åƒï¼ŒæŒ‡å‡ºæ’å›¾åœ¨åŸå›¾ä¸­çš„ box åæ ‡ï¼Œå­—å…¸åˆ—è¡¨ä»¥JSONæ ¼å¼è¾“å‡ºã€‚

åŸå›¾ï¼š"""
    contents_info.append(
        {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
    )
    mime_type = mimetypes.guess_type(original_image_path)[0]
    contents_info.append(
        {
            "mime_type": mime_type,
            "part": Image.load_from_file(original_image_path),
            "duration": None,
        }
    )
    prompt = f"æå–çš„æ–‡æœ¬ï¼š{extracted_text}\n\nåˆ†ç¦»çš„å›¾ç‰‡ï¼š"
    contents_info.append(
        {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
    )
    mime_type = mimetypes.guess_type(separated_image_path)[0]
    contents_info.append(
        {
            "mime_type": mime_type,
            "part": Image.load_from_file(separated_image_path),
            "duration": None,
        }
    )
    prompt = """è¾“å‡ºç¤ºä¾‹ï¼š
```json
[
    {
        "x": 0,
        "y": 0,
        "width": 100,
        "height": 100
    },
]
```  
"""
    contents_info.append(
        {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
    )
    return contents_info


def process_file_and_prompt(uploaded_file, prompt):
    # æ²¡æœ‰æ¡ˆä¾‹
    contents_info = []
    if uploaded_file is not None:
        contents_info.append(_process_media(uploaded_file))
    contents_info.append(
        {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
    )
    return contents_info


def view_example(container, prompt):
    container.markdown("##### æç¤ºè¯")
    container.markdown(prompt)


def get_prompt_templature(op):
    question = st.session_state["math-question"]
    # if not question:
    #     st.error("è¯·å…ˆæå–æ•°å­¦è¯•é¢˜æ–‡æœ¬ã€‚")
    #     st.stop()
    if op == "æä¾›è§£é¢˜æ€è·¯":
        return SOLUTION_THOUGHT_PROMPT.format(
            grade=grade,
            question=question,
            question_type=question_type,
            exmples=EXAMPLES,
        )
    elif op == "æå–å›¾ä¸­çš„è¯•é¢˜":
        return EXTRACT_TEST_QUESTION_PROMPT.format(question=question, exmples=EXAMPLES)
    elif op == "æä¾›å®Œæ•´è§£ç­”":
        return ANSWER_MATH_QUESTION_PROMPT.format(
            grade=grade,
            question=question,
            question_type=question_type,
            exmples=EXAMPLES,
        )
    return ""


def replace_brackets_with_dollar(content):
    content = content.replace("\\(", "$").replace("\\)", "$")
    return content


def display_in_container(container, content, code_fmt=False):
    if not code_fmt:
        container.markdown(
            replace_brackets_with_dollar(content), unsafe_allow_html=True
        )
    else:
        container.code(replace_brackets_with_dollar(content), language="markdown")


def ensure_math_code_wrapped_with_dollar(math_code):
    if not (math_code.startswith("$") and math_code.endswith("$")):
        math_code = f"${math_code}$"
    return math_code


@st.cache_data(
    ttl=timedelta(hours=1), show_spinner="æ­£åœ¨è¿è¡Œå¤šæ¨¡æ€æ¨¡å‹ï¼Œæå–æ•°å­¦è¯•é¢˜..."
)
def extract_math_question_text_for(uploaded_file, prompt):
    contents = process_file_and_prompt(uploaded_file, prompt)
    model_name = "gemini-1.0-pro-vision-001"
    model = load_vertex_model(model_name)
    generation_config = GenerationConfig(
        temperature=0.0,
        top_p=1.0,
        top_k=32,
        max_output_tokens=2048,
    )
    return parse_generated_content_and_update_token(
        "å¤šæ¨¡æ€AIæå–æ•°å­¦é¢˜æ–‡æœ¬",
        model_name,
        model.generate_content,
        contents,
        generation_config,
        stream=False,
    )


@st.cache_data(
    ttl=timedelta(hours=1), show_spinner="æ­£åœ¨è¿è¡Œå¤šæ¨¡æ€æ¨¡å‹ï¼Œè§£ç­”æ•°å­¦è¯•é¢˜..."
)
def answer_math_question_for(uploaded_file, prompt):
    contents = process_file_and_prompt(uploaded_file, prompt)
    model_name = "gemini-1.0-pro-vision-001"
    model = load_vertex_model(model_name)
    generation_config = GenerationConfig(
        temperature=0.0,
        top_p=1.0,
        top_k=32,
        max_output_tokens=2048,
    )
    return parse_generated_content_and_update_token(
        "å¤šæ¨¡æ€AIè§£ç­”æ•°å­¦è¯•é¢˜",
        model_name,
        model.generate_content,
        contents,
        generation_config,
        stream=False,
    )


def gen_tip_for(question):
    Assistant_Configuration = {
        "temperature": 0.0,
        "top_k": 32,
        "top_p": 1.0,
        "max_output_tokens": 1024,
    }
    question = f"ä½ ç²¾é€š Markdown æ•°å­¦å…¬å¼è¯­æ³•ã€‚è¯·ä¸“æ³¨äºå›ç­”ä¸ Markdown æ•°å­¦å…¬å¼ç›¸å…³çš„é—®é¢˜ã€‚å¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸æ­¤æ— å…³ï¼Œä»¥ç¤¼è²Œçš„æ–¹å¼å¼•å¯¼ä»–ä»¬æå‡ºç›¸å…³é—®é¢˜ã€‚ç°åœ¨ï¼Œè¯·ä¸ºä»¥ä¸‹é—®é¢˜æä¾› Markdown æ•°å­¦å…¬å¼ä»£ç ï¼ˆä¸éœ€è¦åŒ–ç®€ï¼‰ï¼š{question}"
    assistant_config = GenerationConfig(**Assistant_Configuration)
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(question), "duration": None}
    ]
    response = parse_generated_content_and_update_token(
        "AI Formula Assistant",
        "gemini-pro",
        st.session_state["AI-Formula-Assistant"].send_message,
        contents_info,
        assistant_config,
        stream=False,
    )
    return response.replace("```", "")


def update_slider_max():
    # è¯»å–å›¾åƒ
    uploaded_file = st.session_state.uploaded_file
    if uploaded_file is None:
        return
    image_data = uploaded_file.getvalue()
    image = PIL_Image.open(io.BytesIO(image_data))

    st.session_state["default_width"] = image.width
    st.session_state["default_height"] = image.height

    # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„æ»‘å—æœ€å¤§å€¼
    st.session_state["right"] = image.width
    st.session_state["bottom"] = image.height


# endregion

# region langchain


def create_math_chat():
    # if uploaded_file is None:
    #     return
    st.session_state["math-assistant"] = ChatVertexAI(
        model_name="gemini-1.0-pro-vision-001",
        # convert_system_message_to_human=True,
        safety_settings={
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE
        },
    )


def _process_image(image_data):
    mime_type = "image/png"
    # ç”¨æ–‡ä»¶æ‰©å±•åç§°å½¢æˆ MIME ç±»å‹
    p = Part.from_data(data=image_data, mime_type=mime_type)  # type: ignore
    duration = None
    return {"mime_type": mime_type, "part": p, "duration": duration}


def process_image_and_prompt(image_data, prompt):
    # æ²¡æœ‰æ¡ˆä¾‹
    contents_info = []
    if uploaded_file is not None:
        contents_info.append(_process_image(image_data))
    contents_info.append(
        {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
    )
    return contents_info


@st.cache_data(
    ttl=timedelta(hours=1), show_spinner="æ­£åœ¨è¿è¡Œå¤šæ¨¡æ€æ¨¡å‹ï¼Œæå–æ•°å­¦è¯•é¢˜..."
)
def extract_math_text_for(image_data, prompt):
    contents = process_image_and_prompt(image_data, prompt)
    model_name = "gemini-1.0-pro-vision-001"
    model = load_vertex_model(model_name)
    generation_config = GenerationConfig(
        temperature=0.0,
        top_p=1.0,
        top_k=32,
        max_output_tokens=2048,
    )
    return parse_generated_content_and_update_token(
        "å¤šæ¨¡æ€AIæå–æ•°å­¦é¢˜æ–‡æœ¬",
        model_name,
        model.generate_content,
        contents,
        generation_config,
        stream=False,
    )


def extract_math_question(byte_data):
    question = st.session_state["math-question"]
    question = extract_math_text_for(
        byte_data,
        EXTRACT_TEST_QUESTION_PROMPT.format(question=question, exmples=EXAMPLES),
    )
    # st.session_state["math-question"] = replace_brackets_with_dollar(question)
    st.session_state["math-question"] = question


def is_blank(image):
    # å°†å›¾åƒè½¬æ¢ä¸º numpy æ•°ç»„
    img_array = np.array(image)

    # æ£€æŸ¥æ‰€æœ‰åƒç´ å€¼æ˜¯å¦éƒ½ç›¸åŒ
    return np.all(img_array == img_array[0, 0])


@st.cache_data(ttl=timedelta(hours=1), show_spinner=False)
def run_chain(prompt):
    uploaded_file = st.session_state["math-illustration"]
    text_message = {
        "type": "text",
        "text": prompt,
    }
    if uploaded_file is not None:
        message = HumanMessage(
            content=[
                text_message,
                image_to_dict(uploaded_file),
            ]
        )
    else:
        message = HumanMessage(content=[text_message])
    return st.session_state["math-assistant"].invoke(
        [message],
    )


# endregion

# region ä¾§è¾¹æ 
# æ£€æŸ¥ä¼šè¯çŠ¶æ€ä¸­æ˜¯å¦å·²ç»æœ‰é»˜è®¤çš„å±å¹•å®½åº¦å’Œé«˜åº¦ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™è®¾ç½®ä¸ºé»˜è®¤å€¼
if "default_width" not in st.session_state:
    st.session_state["default_width"] = 1920
if "default_height" not in st.session_state:
    st.session_state["default_height"] = 1080

# æ£€æŸ¥ä¼šè¯çŠ¶æ€ä¸­æ˜¯å¦å·²ç»æœ‰æ»‘å—çš„å€¼ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™è®¾ç½®ä¸ºé»˜è®¤å€¼
if "left" not in st.session_state:
    st.session_state["left"] = 0
if "top" not in st.session_state:
    st.session_state["top"] = 0
if "right" not in st.session_state:
    st.session_state["right"] = st.session_state["default_width"]
if "bottom" not in st.session_state:
    st.session_state["bottom"] = st.session_state["default_height"]


def on_slider_change(elem):
    has_graph = st.session_state["has_graph"]
    if not has_graph:
        elem.warning("é€‰é¡¹å¡æœªé€‰ä¸­æ’å›¾ï¼Œæ»‘å—è£å‰ªæ— æ•ˆã€‚")


st.sidebar.subheader(
    "æ’å›¾è£å‰ª",
    help="""âœ¨ ä½¿ç”¨æ»‘å—æ¥è°ƒæ•´æ’å›¾çš„è£å‰ªåŒºåŸŸã€‚"ä¸Š" å’Œ "ä¸‹" æ»‘å—æ§åˆ¶è£å‰ªåŒºåŸŸçš„ä¸Šè¾¹ç•Œå’Œä¸‹è¾¹ç•Œï¼Œ"å·¦" å’Œ "å³" æ»‘å—æ§åˆ¶è£å‰ªåŒºåŸŸçš„å·¦è¾¹ç•Œå’Œå³è¾¹ç•Œã€‚""",
)
sidebar_status = st.sidebar.empty()
# åˆ›å»ºæ»‘å—ï¼Œä½¿ç”¨ä¼šè¯çŠ¶æ€ä¸­çš„å€¼ä½œä¸ºé»˜è®¤å€¼
top = st.sidebar.slider(
    "ä¸Š",
    0,
    st.session_state["default_height"],
    st.session_state["top"],
    key="sidebar-image-top",
    on_change=on_slider_change,
    args=(sidebar_status,),
)
bottom = st.sidebar.slider(
    "ä¸‹",
    0,
    st.session_state["default_height"],
    st.session_state["bottom"],
    key="sidebar-image-bottom",
    on_change=on_slider_change,
    args=(sidebar_status,),
)
left = st.sidebar.slider(
    "å·¦",
    0,
    st.session_state["default_width"],
    st.session_state["left"],
    key="sidebar-image-left",
    on_change=on_slider_change,
    args=(sidebar_status,),
)
right = st.sidebar.slider(
    "å³",
    0,
    st.session_state["default_width"],
    st.session_state["right"],
    key="sidebar-image-right",
    on_change=on_slider_change,
    args=(sidebar_status,),
)

# endregion

# region ä¸»é¡µ


if "math-assistant" not in st.session_state:
    create_math_chat()

# region tabs
st.subheader(":bulb: :blue[æ•°å­¦è§£é¢˜åŠ©æ‰‹]", divider="rainbow", anchor=False)
tab1, tab2, tab3, tab4 = st.tabs(["1ï¸âƒ£ ä¸Šä¼ å›¾ç‰‡", "2ï¸âƒ£ æ£€éªŒè§£æ", "3ï¸âƒ£ è®¾ç½®","4ï¸âƒ£ è§£ç­”"])
# endregion

st.markdown("""âœ¨ :red[è¯·ä¸Šä¼ æ¸…æ™°ã€æ­£é¢ã€æœªæ—‹è½¬çš„æ•°å­¦è¯•é¢˜å›¾ç‰‡ã€‚]""")
elem_cols = st.columns([10, 1, 10])
uploaded_file = elem_cols[0].file_uploader(
    "ä¸Šä¼ æ•°å­¦è¯•é¢˜å›¾ç‰‡ã€ç‚¹å‡»`Browse files`æŒ‰é’®ï¼Œä»æœ¬åœ°ä¸Šä¼ æ–‡ä»¶ã€‘",
    accept_multiple_files=False,
    key="uploaded_file",
    type=["png", "jpg"],
    on_change=update_slider_max,
    help="""
æ”¯æŒçš„æ ¼å¼
- å›¾ç‰‡ï¼šPNGã€JPG
""",
)
grade_cols = elem_cols[2].columns(3)
grade = grade_cols[0].selectbox(
    "å¹´çº§", ["å°å­¦", "åˆä¸­", "é«˜ä¸­", "å¤§å­¦"], key="grade", help="é€‰æ‹©å¹´çº§"
)
question_type = grade_cols[1].selectbox(
    "é¢˜å‹",
    ["é€‰æ‹©é¢˜", "å¡«ç©ºé¢˜", "è®¡ç®—é¢˜", "è¯æ˜é¢˜", "åˆ¤æ–­é¢˜", "æ¨ç†é¢˜", "è§£ç­”é¢˜"],
    # index=None,
    key="question_type",
    help="é€‰æ‹©é¢˜å‹",
)
operation = grade_cols[2].selectbox(
    "æ‚¨çš„æ“ä½œ",
    ["æä¾›è§£é¢˜æ€è·¯", "æä¾›å®Œæ•´è§£ç­”"],
    key="operation",
)
has_graph = grade_cols[0].checkbox(
    "æ˜¯å¦æœ‰æ’å›¾",
    key="has_graph",
    value=False,
    help="âœ¨ è¯·å‹¾é€‰æ­¤é¡¹ï¼Œå¦‚æœæ‚¨çš„è¯•é¢˜ä¸­åŒ…å«æ’å›¾ã€‚åˆ†ç¦»æ’å›¾å¯ä»¥æé«˜OCRå¯¹æ–‡æœ¬çš„è¯†åˆ«å‡†ç¡®æ€§ã€‚",
)


def crop_and_highlight_image(uploaded_file, left, top, right, bottom, has_graph):
    image_data = uploaded_file.getvalue()
    img = PIL_Image.open(io.BytesIO(image_data))
    # åªåœ¨éœ€è¦æ—¶è½¬æ¢å›¾åƒ
    if img.mode != "RGB":
        img = img.convert("RGB")
    illustration_image = PIL_Image.new("RGB", img.size, (255, 255, 255))
    illustration_image = illustration_image.convert("RGB")
    if not has_graph:
        return img, illustration_image, img

    if left >= right:
        st.error(
            f"è£å‰ªåŒºåŸŸæ— æ•ˆï¼Œå·¦è¾¹ç•Œï¼ˆ{left}ï¼‰ä¸èƒ½å¤§äºæˆ–ç­‰äºå³è¾¹ç•Œï¼ˆ{right}ï¼‰ï¼Œè¯·é‡æ–°è®¾ç½®ã€‚"
        )
        st.stop()

    if top >= bottom:
        st.error(
            f"è£å‰ªåŒºåŸŸæ— æ•ˆï¼Œä¸Šè¾¹ç•Œï¼ˆ{top}ï¼‰ä¸èƒ½å¤§äºæˆ–ç­‰äºä¸‹è¾¹ç•Œï¼ˆ{bottom}ï¼‰ï¼Œè¯·é‡æ–°è®¾ç½®ã€‚"
        )
        st.stop()

    img_copy = img.copy()
    cropped_image = img_copy.crop((left, top, right, bottom))
    draw = ImageDraw.Draw(img_copy)
    draw.rectangle([left, top, right, bottom], outline="red")
    offset = 20  # åç§»é‡
    draw.text((left + offset, top + offset), "left", fill="blue")
    draw.text((right - offset, top + offset), "top", fill="blue")
    draw.text((left + offset, bottom - offset), "right", fill="blue")
    draw.text((right - offset, bottom - offset), "bottom", fill="blue")

    illustration_image.paste(cropped_image, (left, top))
    text_image = ImageChops.difference(img, illustration_image)
    text_image = ImageOps.invert(text_image)

    return img_copy, illustration_image, text_image


images_cols = st.columns(3)

if uploaded_file is not None:
    img_copy, illustration_image, text_image = crop_and_highlight_image(
        uploaded_file, left, top, right, bottom, has_graph
    )
    # st.write(f"æ’å›¾æ˜¯å¦ä¸ºç©ºï¼š{is_blank(illustration_image)}")
    images_cols[0].markdown("åŸå›¾")
    images_cols[0].image(img_copy, use_column_width=True, caption="åŸå›¾")
    images_cols[1].markdown("æ’å›¾")
    images_cols[1].image(illustration_image, use_column_width=True, caption="æ’å›¾")
    images_cols[2].markdown("æ–‡æœ¬")
    images_cols[2].image(text_image, use_column_width=True, caption="æ–‡æœ¬")


prompt_cols = st.columns([1, 1])
prompt_cols[0].markdown("æ‚¨çš„æç¤ºè¯")
prompt = prompt_cols[0].text_area(
    "æ‚¨çš„æç¤ºè¯",
    # value=st.session_state["math-question-prompt"],
    key="user_prompt_key",
    placeholder="è¾“å…¥æç¤ºè¯æˆ–ç‚¹å‡»`æ¨¡æ¿`æŒ‰é’®é€‰æ‹©æç¤ºè¯ã€‚",
    max_chars=12288,
    height=300,
    label_visibility="collapsed",
)

prompt_cols[1].markdown("æ˜¾ç¤ºéªŒè¯", help="âœ¨ æ˜¾ç¤ºéªŒè¯æç¤ºè¯ä¸­çš„æ•°å­¦å…¬å¼")
view_prompt_container = prompt_cols[1].container(height=300)
view_prompt_container.markdown(prompt, unsafe_allow_html=True)

status = st.empty()
tab0_btn_cols = st.columns([1, 1, 1, 1, 1, 5])
cls_btn = tab0_btn_cols[0].button(
    "æ¸…é™¤[:wastebasket:]",
    help="âœ¨ æ¸…ç©ºæç¤ºè¯",
    key="reset_text_value",
    on_click=reset_text_value,
    args=("user_prompt_key",),
)
extract_btn = tab0_btn_cols[1].button(
    "æå–[:scissors:]", key="extract_btn", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæå–æ•°å­¦è¯•é¢˜æ–‡æœ¬ã€‚"
)
code_btn = tab0_btn_cols[2].button(
    "ä»£ç [ğŸ“œ]",
    key="code_btn",
    help="âœ¨ æ˜¾ç¤ºæ•°å­¦è¯•é¢˜çš„Markdownæ•°å­¦ä»£ç ï¼Œç‚¹å‡»æ¡†å†…çš„å¤åˆ¶æŒ‰é’®è¿›è¡Œå¤åˆ¶ã€‚",
)
prompt_btn = tab0_btn_cols[3].button(
    "æ¨¡æ¿[:eyes:]",
    key="demo_prompt_text",
    help="âœ¨ å±•ç¤ºå½“å‰æ‰€åº”ç”¨çš„æç¤ºè¯æ¨¡æ¿",
    # on_click=reset_text_value,
    # args=(
    #     "user_prompt_key",
    #     get_prompt_templature(
    #         operation,
    #     ),
    # ),
)
ans_btn = tab0_btn_cols[4].button(
    "è§£ç­”[:black_nib:]", key="generate_button", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œè·å–AIå“åº”ã€‚"
)


response_container = st.container(height=300)
prompt_elem = st.empty()

if extract_btn:
    response_container.empty()
    if has_graph and is_blank(illustration_image):
        status.error("å›¾ç‰‡ä¸­çš„æ’å›¾éƒ¨åˆ†ä¸ºç©ºï¼Œè¯·é‡æ–°è£å‰ªå›¾ç‰‡ã€‚")
        st.stop()
    if uploaded_file:
        img_copy, illustration_image, text_image = crop_and_highlight_image(
            uploaded_file, left, top, right, bottom, has_graph
        )
        if is_blank(text_image):
            status.error("å›¾ç‰‡ä¸­çš„æ–‡æœ¬éƒ¨åˆ†ä¸ºç©ºï¼Œè¯·é‡æ–°è£å‰ªå›¾ç‰‡ã€‚")
            st.stop()
        # å‡è®¾ text_image æ˜¯ä½ çš„ PIL å›¾åƒå¯¹è±¡
        output = io.BytesIO()
        text_image.save(output, format="PNG")
        byte_data = output.getvalue()
        ocr = mathpix_ocr_read(byte_data, False)
        st.session_state["math-question"] = ocr["text"]
        # logger.info(f'ocr math-question: {ocr["text"]}')
        # extract_math_question(byte_data)

display_in_container(response_container, st.session_state["math-question"])

if cls_btn:
    st.session_state["math-question"] = ""

if code_btn:
    response_container.empty()
    display_in_container(response_container, st.session_state["math-question"], True)

if prompt_btn:
    prompt = get_prompt_templature(operation)
    view_prompt_container.markdown(prompt, unsafe_allow_html=True)

if ans_btn:
    # if uploaded_file is None:
    #     if operation == "æå–å›¾ä¸­çš„è¯•é¢˜":
    #         status.error(
    #             "æ‚¨æ˜¯å¦éœ€è¦ä»å›¾åƒä¸­æå–è¯•é¢˜æ–‡æœ¬ï¼Ÿç›®å‰ä¼¼ä¹è¿˜æœªæ¥æ”¶åˆ°æ‚¨ä¸Šä¼ çš„æ•°å­¦ç›¸å…³å›¾ç‰‡ã€‚è¯·ä¸Šä¼ å›¾ç‰‡ï¼Œä»¥ä¾¿ AI èƒ½æ›´å‡†ç¡®åœ°ç†è§£å’Œå›ç­”æ‚¨çš„é—®é¢˜ã€‚"
    #         )
    #         st.stop()
    if not prompt:
        status.error("è¯·æ·»åŠ æç¤ºè¯")
        st.stop()
    response_container.empty()
    view_example(response_container, prompt)
    answer = answer_math_question_for(uploaded_file, prompt)
    response_container.markdown("##### AIå“åº”")
    display_in_container(response_container, answer)
    update_sidebar_status(sidebar_status)

# endregion


# region æ•°å­¦å…¬å¼ç¼–è¾‘
st.subheader("æ•°å­¦å…¬å¼ç¼–è¾‘æ¼”ç¤º", divider="rainbow", anchor="æ•°å­¦å…¬å¼ç¼–è¾‘")

demo_cols = st.columns([10, 1, 10])
demo_cols[0].markdown("åœ¨æ­¤è¾“å…¥åŒ…å«æ•°å­¦å…¬å¼çš„markdownæ ¼å¼æ–‡æœ¬")
MATH_VARIABLE_DEMO = r"$x$"
FRACTION_DEMO = r"$\frac{a}{b}$"  # åˆ†æ•°ï¼Œa/b
SUBSCRIPT_DEMO = r"$a_{i}$"  # ä¸‹æ ‡ï¼Œa_i
FORMULA_DEMO = r"$a^2 + b^2 = c^2$"  # å…¬å¼ï¼Œå‹¾è‚¡å®šç†
INTEGRAL_DEMO = r"$$\int_0^\infty \frac{1}{x^2}\,dx$$"  # ç§¯åˆ†
DEMO = f"""\
#### æ•°å­¦å…¬å¼ç¼–è¾‘æ¼”ç¤º
##### è¡Œå†…æ•°å­¦å…¬å¼
- è¡Œå†…å˜é‡ä»£ç  ```{MATH_VARIABLE_DEMO}``` æ˜¾ç¤ºï¼š{MATH_VARIABLE_DEMO}
- åˆ†æ•°ä»£ç  ```{FRACTION_DEMO}``` æ˜¾ç¤ºï¼š{FRACTION_DEMO}
- ä¸‹æ ‡ä»£ç  ```{SUBSCRIPT_DEMO}``` æ˜¾ç¤ºï¼š{SUBSCRIPT_DEMO}
- å…¬å¼ä»£ç  ```{FORMULA_DEMO}``` æ˜¾ç¤ºï¼š{FORMULA_DEMO}
##### å—çº§æ•°å­¦å…¬å¼
- ç§¯åˆ†ä»£ç  ```{INTEGRAL_DEMO}``` æ˜¾ç¤ºï¼š{INTEGRAL_DEMO}
"""
math_text = demo_cols[0].text_area(
    "è¾“å…¥æ•°å­¦å…¬å¼",
    label_visibility="collapsed",
    key="demo-math-text",
    height=300,
)


with demo_cols[2]:
    st.markdown("æ£€æŸ¥æ•°å­¦å…¬å¼æ˜¯å¦æ­£ç¡®")
    ai_tip_container = st.container(border=True, height=300)
    with ai_tip_container:
        if math_prompt := st.chat_input("å‘AIæé—®æ•°å­¦å…¬å¼çš„å†™æ³•ï¼Œæ¯”å¦‚ï¼šä¸¾ä¾‹åˆ†æ•°çš„å†™æ³•"):
            if "AI-Formula-Assistant" not in st.session_state:
                initialize_writing_chat()
            math_code = gen_tip_for(math_prompt)
            st.code(
                f"{math_code}",
                language="markdown",
            )

        st.markdown(math_text, unsafe_allow_html=True)

edit_btn_cols = demo_cols[0].columns(4)

demo_btn = edit_btn_cols[0].button(
    "æ¼”ç¤º[:eyes:]",
    key="demo_math_text",
    help="âœ¨ æ¼”ç¤ºæ•°å­¦å…¬å¼",
    on_click=reset_text_value,
    args=("demo-math-text", DEMO),
)
demo_cls_edit_btn = edit_btn_cols[1].button(
    "æ¸…é™¤[:wastebasket:]",
    key="clear_math_text",
    help="âœ¨ æ¸…ç©ºæ•°å­¦å…¬å¼",
    on_click=reset_text_value,
    args=("demo-math-text",),
)
demo_code_btn = edit_btn_cols[2].button(
    "ä»£ç [:clipboard:]",
    key="code_math_text",
    help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå°†åŸå§‹æ–‡æœ¬è½¬æ¢ä¸ºMarkdownæ ¼å¼çš„ä»£ç ï¼Œå¹¶åœ¨å³ä¾§æ˜¾ç¤ºï¼Œä»¥ä¾¿å¤åˆ¶ã€‚",
)

if demo_cls_edit_btn:
    pass

if demo_code_btn:
    st.code(f"{math_text}", language="markdown")

with st.expander(":bulb: æ€æ ·æœ‰æ•ˆåˆ©ç”¨æ•°å­¦åŠ©æ‰‹ï¼Ÿ", expanded=False):
    st.markdown(
        """
- æä¾›æ¸…æ™°ã€æ­£é¢ã€æœªæ—‹è½¬çš„æ•°å­¦è¯•é¢˜å›¾ç‰‡ï¼Œæœ‰åŠ©äºæ¨¡å‹æ›´å‡†ç¡®åœ°è¯†åˆ«æ•°å­¦å…¬å¼å’Œè§£ç­”ã€‚
- å¦‚æœæ¨¡å‹å¯¹åˆ†æ•°çš„è¯†åˆ«æ•ˆæœä¸å¥½æˆ–ä»è¯•é¢˜æ–‡æœ¬ä¸­æå–çš„ä¿¡æ¯æœ‰è¯¯ï¼Œä¿®æ­£æ–‡æœ¬ä¸­çš„é—®é¢˜åå†å°è¯•è®©æ¨¡å‹è¿›è¡Œè§£ç­”ã€‚
- :warning: è™½ç„¶æ¨¡å‹å¯ä»¥å¸®åŠ©è§£ææ•°å­¦é—®é¢˜ï¼Œä½†å®ƒå¹¶ä¸å®Œç¾ï¼Œä¸èƒ½æ›¿ä»£äººçš„åˆ¤æ–­å’Œç†è§£ã€‚
"""
    )

with st.expander(":bulb: å¦‚ä½•ç¼–è¾‘æ•°å­¦å…¬å¼ï¼Ÿ", expanded=False):
    st.markdown("å¸¸ç”¨æ•°å­¦ç¬¦å·ç¤ºä¾‹ä»£ç ")
    # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸€é¡¹åŒ…æ‹¬åç§°ã€LaTeX ä»£ç ã€Markdown ä»£ç å’Œç¤ºä¾‹
    math_symbols = [
        ["åˆ†æ•°", r"\frac{a}{b}", r"\frac{a}{b}", r"\frac{a}{b}"],
        ["å¹³æ–¹", r"x^2", r"x^2", r"x^2"],
        ["ç«‹æ–¹", r"x^3", r"x^3", r"x^3"],
        ["æ±‚å’Œ", r"\sum_{i=1}^n a_i", r"\sum_{i=1}^n a_i", r"\sum_{i=1}^n a_i"],
        ["ç§¯åˆ†", r"\int_a^b f(x) dx", r"\int_a^b f(x) dx", r"\int_a^b f(x) dx"],
    ]

    math_demo_cols = st.columns(4)
    math_demo_cols[0].markdown("åç§°")
    math_demo_cols[1].markdown("LaTeX")
    math_demo_cols[2].markdown("Markdown")
    math_demo_cols[3].markdown("æ˜¾ç¤ºæ•ˆæœ")
    for symbol in math_symbols:
        math_demo_cols[0].markdown(symbol[0])
        math_demo_cols[1].text(symbol[1])
        math_demo_cols[2].text(symbol[2])
        math_demo_cols[3].markdown(f"${symbol[3]}$")

    url = "https://cloud.tencent.com/developer/article/2349331"
    st.markdown(f"æ›´å¤šæ•°å­¦å…¬å¼ç¼–è¾‘ï¼Œè¯·å‚è€ƒ [æ•°å­¦å…¬å¼è¯­æ³•é›†]( {url} )ã€‚")

# endregion
