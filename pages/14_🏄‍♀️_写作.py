from datetime import timedelta
import difflib
import logging
from functools import partial

import spacy
import streamlit as st
from langdetect import detect
from vertexai.preview.generative_models import Content, GenerationConfig, Part

from menu import menu
from gailib.google_ai import (
    display_generated_content_and_update_token,
    load_vertex_model,
    parse_generated_content_and_update_token,
    parse_json_string,
    to_contents_info,
)
from gailib.html_constants import TIPPY_JS
from gailib.html_fmt import (
    display_grammar_errors,
    display_word_spell_errors,
    remove_markup,
)
from gailib.st_helper import (
    add_exercises_to_db,
    check_access,
    configure_google_apis,
    on_project_changed,
    setup_logger,
    update_sidebar_status,
)

# region é…ç½®

# åˆ›å»ºæˆ–è·å–loggerå¯¹è±¡


logger = logging.getLogger("streamlit")
setup_logger(logger)

st.set_page_config(
    page_title="å†™ä½œç»ƒä¹ ",
    page_icon="ğŸ„â€â™€ï¸",
    layout="wide",
)
menu()
check_access(False)
if st.session_state.role not in [
        "ç”¨æˆ·",
        "è¶…çº§ç”¨æˆ·",
        "ç®¡ç†å‘˜",
    ]:
    st.error("æ‚¨æ²¡æœ‰æƒé™è®¿é—®æ­¤é¡µé¢ã€‚")
    st.stop()

configure_google_apis()
on_project_changed("å†™ä½œç»ƒä¹ ")
add_exercises_to_db()
sidebar_status = st.sidebar.empty()

# endregion

# region ä¼šè¯

if "text-model" not in st.session_state:
    st.session_state["text-model"] = load_vertex_model("gemini-pro")

if "writing-content" not in st.session_state:
    st.session_state["writing-content"] = ""

if "writing-ai-prompt" not in st.session_state:
    st.session_state["writing-ai-prompt"] = ""

if "writing-ai-assitant" not in st.session_state:
    st.session_state["writing-ai-assitant"] = ""

# Use the get method since the keys won't be in session_state on the first script run
if st.session_state.get("writing-clear"):
    st.session_state["writing-text"] = ""

# endregion

# region è¾¹æ 

# endregion


# region å‡½æ•°


def clear_text(key):
    st.session_state[key] = ""


def initialize_writing_chat():
    model_name = "gemini-pro"
    model = load_vertex_model(model_name)
    history = [
        Content(
            role="user",
            parts=[
                Part.from_text(
                    "æ‚¨æ˜¯ä¸€åè‹±è¯­å†™ä½œè¾…å¯¼è€å¸ˆï¼Œæ‚¨çš„è§’è‰²ä¸ä»…æ˜¯æŒ‡å¯¼ï¼Œæ›´æ˜¯æ¿€å‘å­¦ç”Ÿçš„åˆ›ä½œæ½œåŠ›ã€‚æ‚¨éœ€è¦è€å¿ƒåœ°å¼•å¯¼å­¦ç”Ÿï¼Œè€Œä¸æ˜¯ç›´æ¥ç»™å‡ºå®Œæ•´çš„ç­”æ¡ˆã€‚é€šè¿‡æä¾›æç¤ºå’ŒæŒ‡å¯¼ï¼Œå¸®åŠ©ä»–ä»¬åŸ¹å…»å’Œæå‡å†™ä½œæŠ€èƒ½ã€‚æ‚¨çš„å›å¤å§‹ç»ˆç”¨è‹±è¯­ï¼Œé™¤éå­¦ç”Ÿè¦æ±‚æ‚¨ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚å¦‚æœå­¦ç”Ÿæå‡ºä¸å†™ä½œæ— å…³çš„é—®é¢˜ï¼Œæ‚¨éœ€è¦ä»¥å©‰è½¬çš„æ–¹å¼å¼•å¯¼ä»–ä»¬å›åˆ°ä¸»é¢˜ã€‚"
                )
            ],
        ),
        Content(role="model", parts=[Part.from_text("Alright, let's proceed.")]),
    ]
    st.session_state["writing-chat"] = model.start_chat(history=history)


GRAMMAR_CHECK_TEMPLATE = """\
As an English grammar expert, your primary task is to inspect and correct any grammatical errors in the following "Article".

Step by step, complete the following:
1. Identify all grammatical inaccuracies in the article, including errors in tense usage, noun forms, subject-verb agreement, use of prepositions and conjunctions, punctuation, and capitalization.Spelling errors that lead to incorrect word forms or parts of speech are considered related to grammar and should be corrected. Other spelling errors that do not affect the grammatical structure of the sentence are disregarded in this check.
2. In the event that the article is devoid of grammatical inaccuracies, yield an empty dictionary.
3. Rectify the identified grammatical inaccuracies based on the original text.
    - First, use `~~` to mark the segments that are to be removed from the original text. Then, use `<ins>` `</ins>` to indicate the additions.
    - Any modifications to the original text, including the addition of white space, punctuation, and changes in case, should be distinctly indicated using the above markers.
    - Please note that the preferred method of indicating corrections is to mark the entire word for deletion and then insert the corrected word. 
    - The "corrected" content should clearly articulate the modifications made from the original text.
4. Provide a corresponding explanation for each modification made, then compile these explanations into a list.
5. Output a dictionary with "corrected" (the corrected text) and "explanations" (the list of explanations) as keys.
6. Finally, output the dictionary in JSON format.

Examples:

The original text: 'I have many moeney in the past,I have not to work now.'
The output dictionary should include the following keys:
- corrected: "I ~~have~~ <ins>had</ins> many moeney in the past, so I ~~have not to~~ <ins>don't have to</ins> work now."
- explanations: ["The past tense of 'have' is 'had'.", "The phrase 'have not to' is used to express necessity or obligation. In this context, it should be replaced with 'don't have to' to convey the idea of not being required to work."]

The original text: 'She don't likes apples.'
The output dictionary should include the following keys:
- corrected: "She ~~don't likes~~ <ins>doesn't like</ins> apples."
- explanations: ["The correct form is 'doesn't like' when referring to third person singular."]   

The original text: 'she is a teacher.'
The output dictionary should include the following keys:
- corrected: "~~she~~ <ins>She</ins> is a teacher."
- explanations: ["The first word of a sentence should be capitalized."]

Article:
{article}
"""


GRAMMAR_CHECK_CONFIG = {"max_output_tokens": 2048, "temperature": 0.0}


@st.cache_data(ttl=timedelta(days=1), show_spinner="æ­£åœ¨æ£€æŸ¥è¯­æ³•...")
def check_grammar(article):
    # æ£€æŸ¥ article æ˜¯å¦ä¸ºè‹±æ–‡æ–‡æœ¬ [å­—ç¬¦æ•°é‡å°‘å®¹æ˜“è¢«é”™åˆ¤]
    detected_language = detect(article)
    if detected_language in ["zh-cn", "ja"]:
        return {
            "corrected": f"The anticipated language is English, however, {detected_language} was detected",
            "explanations": [],
            "error_type": "LanguageError",
        }

    prompt = GRAMMAR_CHECK_TEMPLATE.format(article=article)
    contents = [prompt]
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(content), "duration": None}
        for content in contents
    ]
    model = st.session_state["text-model"]
    result = parse_generated_content_and_update_token(
        "å†™ä½œç»ƒä¹ -è¯­æ³•æ£€æŸ¥",
        "gemini-pro",
        model.generate_content,
        contents_info,
        GenerationConfig(**GRAMMAR_CHECK_CONFIG),
        stream=False,
        parser=partial(parse_json_string, prefix="```json", suffix="```"),
    )
    result["error_type"] = "GrammarError"
    result["character_count"] = (
        f"{len(article)} / {len(remove_markup(result['corrected']))} characters corrected"
    )
    return result


WORD_SPELL_CHECK_TEMPLATE = """\
As an English writing instructor, your primary task is to inspect and correct any spelling errors in the following "Article".

Step by step, complete the following:

- Read through the article and identify any spelling errors in the words. This primarily includes errors such as misspelled words.
- Please note that this task does not include correcting capitalization errors at the beginning of sentences. If such errors are encountered, they should be ignored and no changes should be made.
- In the event that the article is devoid of spelling errors, yield an empty dictionary.
- For each correction, three steps need to be completed: 1. Deletion of the error, marked with ~~. 2. Addition of the correction, marked with <ins> </ins>. 3. Addition of the explanation for the correction to the "explanations" list. If the correction involves adding a word, delete the word that is in the wrong context first, then add the corrected phrase. 
- Output a dictionary with "corrected" (the corrected text) and "explanations" (the list of explanations) as keys.
- Finally, output the dictionary in JSON format.

Examples:

The original text: 'It help us to learn new things and to develop our skills. It also help us to get a good job and to make a differents in the world.'
The output dictionary should include the following keys:
- corrected: "It ~~help~~ <ins>helps</ins> us to learn new things and to develop our skills. It also ~~help~~ <ins>helps</ins> us to get a good job and to make a ~~differents~~ <ins>difference</ins> in the world."
- explanations: ["The word 'help' should be replaced with 'helps' when the subject is singular.", "The word 'help' should be replaced with 'helps' when the subject is singular.", "The word 'differents' is a misspelling and should be replaced with 'difference'."]

The original text: 'I am going two the store two bye some bred, milk, and egs.'
The output dictionary should include the following keys:
- corrected: "I am going ~~two~~ <ins>to</ins> the store ~~two~~ <ins>to</ins> ~~bye~~ <ins>buy</ins> some ~~bred~~ <ins>bread</ins>, milk, and ~~egs~~ <ins>eggs</ins>."
- explanations: ["The word 'two' is a number and should be replaced with 'to' when used as a preposition.", "The word 'bye' is a farewell expression and should be replaced with 'buy' when referring to purchasing something.", "The word 'bred' is a past tense of breed and should be replaced with 'bread' when referring to the food.", "The word 'egs' is a misspelling and should be replaced with 'eggs'."]

The original text: 'i am going two the store.'
The output dictionary should include the following keys:
- corrected: "i am going ~~two~~ <ins>to</ins> the store."
- explanations: ["The word 'two' is a number and should be replaced with 'to' when used as a preposition."]

Article:
{article}
"""


WORD_SPELL_CHECK_CONFIG = {"max_output_tokens": 2048, "temperature": 0.0}


@st.cache_data(ttl=timedelta(days=1), show_spinner="æ­£åœ¨æ£€æŸ¥å•è¯æ‹¼å†™...")
def check_spelling(article):
    # æ£€æŸ¥ article æ˜¯å¦ä¸ºè‹±æ–‡æ–‡æœ¬ [å­—ç¬¦æ•°é‡å°‘å®¹æ˜“è¢«é”™åˆ¤]
    detected_language = detect(article)
    if detected_language in ["zh-cn", "ja"]:
        return {
            "corrected": f"The anticipated language is English, however, {detected_language} was detected",
            "explanations": [],
            "error_type": "LanguageError",
        }

    prompt = WORD_SPELL_CHECK_TEMPLATE.format(article=article)
    contents = [prompt]
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(content), "duration": None}
        for content in contents
    ]
    model = st.session_state["text-model"]
    result = parse_generated_content_and_update_token(
        "å†™ä½œç»ƒä¹ -æ£€æŸ¥å•è¯æ‹¼å†™",
        "gemini-pro",
        model.generate_content,
        contents_info,
        GenerationConfig(**WORD_SPELL_CHECK_CONFIG),
        stream=False,
        parser=partial(parse_json_string, prefix="```json", suffix="```"),
    )
    result["error_type"] = "WordError"
    result["character_count"] = (
        f"{len(article)} / {len(remove_markup(result['corrected']))} characters corrected"
    )
    return result


ARTICLE_POLISH_TEMPLATE = """\
As an English writing master, your primary task is to utilize your extensive experience to polish the following "Article", ensuring the accuracy and idiomaticity of vocabulary and sentence structure.

Please proceed as follows:

- Carefully read the article and discern the most suitable style and tone based on its theme and purpose.
- Refine and enrich the sentence structure according to the discerned style, and meticulously polish the article.
- If there are no areas in the article that need to be polished, return an empty dictionary.
- Output a dictionary with "corrected" (the revised English text) and "explanation" (the explanation in Simplified Chinese) as keys. The explanation should clearly describe the modifications, reasons, and objectives. Both the corrected text and the explanation should be presented in the form of Markdown formatted text.
- Finally, output the dictionary in JSON format.

Article:
{article}
"""

ARTICLE_POLISH_CONFIG = {"max_output_tokens": 2048, "temperature": 0.75}


@st.cache_data(ttl=timedelta(days=1), show_spinner="æ­£åœ¨æ¶¦è‰²æ–‡ç« ...")
def polish_article(article):
    # æ£€æŸ¥ article æ˜¯å¦ä¸ºè‹±æ–‡æ–‡æœ¬ [å­—ç¬¦æ•°é‡å°‘å®¹æ˜“è¢«é”™åˆ¤]
    detected_language = detect(article)
    if detected_language in ["zh-cn", "ja"]:
        return {
            "corrected": f"The anticipated language is English, however, {detected_language} was detected",
            "explanations": [],
            "error_type": "LanguageError",
        }

    prompt = ARTICLE_POLISH_TEMPLATE.format(article=article)
    contents = [prompt]
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(content), "duration": None}
        for content in contents
    ]
    model = st.session_state["text-model"]
    result = parse_generated_content_and_update_token(
        "å†™ä½œç»ƒä¹ -æ–‡ç« æ¶¦è‰²",
        "gemini-pro",
        model.generate_content,
        contents_info,
        GenerationConfig(**ARTICLE_POLISH_CONFIG),
        stream=False,
        parser=partial(parse_json_string, prefix="```json", suffix="```"),
    )
    result["error_type"] = "WordError"
    result["character_count"] = (
        f"{len(article)} / {len(result['corrected'])} characters corrected"
    )
    return result


LOGIC_STRUCTURE_TEMPLATE = """\
As an English writing assistant, your main task is to ensure that the "article" has a clear structure, a logical sequence, and uses appropriate conjunctions or transition words to represent the logical relationship between different parts.
Please proceed as follows:
- Check the logic and structure of the article, ensure clear viewpoints and sufficient arguments, and ensure clear logical relationships between paragraphs based on the theme of the article.
- If there are no areas for improvement in terms of logic and structure in the article, return an empty dictionary. Otherwise, provide a revised version of the manuscript in English and a detailed explanation of all corrections in Simplified Chinese, both in Markdown format as a single text, using 'corrected' and 'explanation' as the keys in the dictionary.
- Finally, output the result in JSON format.

Article:
{article}
"""

LOGIC_STRUCTURE_CONFIG = {"max_output_tokens": 2048, "temperature": 0.45}


@st.cache_data(ttl=timedelta(days=1), show_spinner="æ­£åœ¨æ£€æŸ¥ã€ä¿®æ­£æ–‡ç« é€»è¾‘ç»“æ„...")
def logic_article(article):
    # æ£€æŸ¥ article æ˜¯å¦ä¸ºè‹±æ–‡æ–‡æœ¬ [å­—ç¬¦æ•°é‡å°‘å®¹æ˜“è¢«é”™åˆ¤]
    detected_language = detect(article)
    if detected_language in ["zh-cn", "ja"]:
        return {
            "corrected": f"The anticipated language is English, however, {detected_language} was detected",
            "explanations": [],
            "error_type": "LanguageError",
        }

    prompt = LOGIC_STRUCTURE_TEMPLATE.format(article=article)
    contents = [prompt]
    contents_info = [
        {"mime_type": "text", "part": Part.from_text(content), "duration": None}
        for content in contents
    ]
    model = st.session_state["text-model"]
    result = parse_generated_content_and_update_token(
        "å†™ä½œç»ƒä¹ -é€»è¾‘ç»“æ„",
        "gemini-pro",
        model.generate_content,
        contents_info,
        GenerationConfig(**LOGIC_STRUCTURE_CONFIG),
        stream=False,
        parser=partial(parse_json_string, prefix="```json", suffix="```"),
    )
    result["error_type"] = "LogicError"
    if result["corrected"]:
        result["character_count"] = (
            f"{len(article)} / {len(result['corrected'])} characters corrected"
        )
    else:
        result["character_count"] = (
            f"{len(article)} / {len(article)} characters corrected"
        )
    return result


# endregion

# region ä¸»ä½“

if "writing_chat_initialized" not in st.session_state:
    initialize_writing_chat()
    st.session_state["writing_chat_initialized"] = True

st.subheader("å†™ä½œç»ƒä¹ ", divider="rainbow", anchor="å†™ä½œç»ƒä¹ ")
st.markdown(
    "æœ¬å†™ä½œç»ƒä¹ æ—¨åœ¨å…¨é¢æå‡æ‚¨çš„å†™ä½œæŠ€å·§å’Œèƒ½åŠ›ã€‚æˆ‘ä»¬æä¾›å¤šç§åœºæ™¯çš„å†™ä½œç»ƒä¹ ï¼Œä»¥å¸®åŠ©æ‚¨åœ¨å„ç§å®é™…æƒ…å¢ƒä¸­æå‡å†™ä½œæŠ€å·§ã€‚AIè¾…åŠ©åŠŸèƒ½å°†åœ¨æ‚¨çš„å†™ä½œè¿‡ç¨‹ä¸­æä¾›è¯­æ³•ã€è¯æ±‡ã€ä¸»é¢˜å’Œé£æ ¼çš„è¯„ä¼°æˆ–ä¿®æ­£ï¼Œç”šè‡³åœ¨éœ€è¦æ—¶æä¾›åˆ›ä½œçµæ„Ÿã€‚è¿™æ˜¯ä¸€ä¸ªå…¨é¢æå‡æ‚¨çš„å†™ä½œèƒ½åŠ›çš„è¿‡ç¨‹ï¼Œæ—¨åœ¨è®©æ‚¨åœ¨å„ç§å†™ä½œåœºæ™¯ä¸­éƒ½èƒ½è‡ªå¦‚åº”å¯¹ã€‚"
)

w_btn_cols = st.columns(8)

# å¸ƒå±€
w_cols = st.columns(3)
HEIGHT = 600

w_cols[0].markdown("<h5 style='color: blue;'>æ‚¨çš„å†™ä½œç»ƒä¹ </h5>", unsafe_allow_html=True)

w_cols[0].text_area(
    "æ‚¨çš„å†™ä½œç»ƒä¹ ",
    max_chars=10000,
    value=st.session_state["writing-content"],
    key="writing-text",
    height=HEIGHT,
    placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    help="åœ¨æ­¤è¾“å…¥æ‚¨çš„ä½œæ–‡",
    label_visibility="collapsed",
)
w_cols[1].markdown("<h5 style='color: green;'>AIå»ºè®®</h5>", unsafe_allow_html=True)
suggestions = w_cols[1].container(border=True, height=HEIGHT)

Assistant_Configuration = {
    "temperature": 0.2,
    "top_k": 32,
    "top_p": 1.0,
    "max_output_tokens": 1024,
}
assistant_config = GenerationConfig(**Assistant_Configuration)
with w_cols[2]:
    on_project_changed("å†™ä½œç»ƒä¹ -AIåŠ©æ•™")
    st.markdown("<h5 style='color: purple;'>AIåŠ©æ•™</h5>", unsafe_allow_html=True)
    ai_tip_container = st.container(border=True, height=HEIGHT)
    with ai_tip_container:
        if prompt := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥ä½ çš„æé—®"):
            contents_info = [
                {"mime_type": "text", "part": Part.from_text(prompt), "duration": None}
            ]
            display_generated_content_and_update_token(
                "AIå†™ä½œåŠ©æ•™",
                "gemini-pro",
                st.session_state["writing-chat"].send_message,
                contents_info,
                assistant_config,
                stream=True,
                placeholder=ai_tip_container.empty(),
            )
            st.session_state["writing-ai-prompt"] = prompt
            st.session_state["writing-ai-assitant"] = (
                st.session_state["writing-chat"].history[-1].parts[0].text
            )
            update_sidebar_status(sidebar_status)

    if st.session_state["writing-ai-prompt"]:
        ai_tip_container.empty()
        ai_tip_container.markdown("ç”¨æˆ·ï¼š")
        ai_tip_container.markdown(st.session_state["writing-ai-prompt"])
        ai_tip_container.divider()
        ai_tip_container.markdown("AIï¼š")
        ai_tip_container.markdown(st.session_state["writing-ai-assitant"])


rfh_btn = w_btn_cols[0].button(
    "åˆ·æ–°[:arrows_counterclockwise:]",
    key="writing-refresh",
    help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œå¼€å§‹æ–°ä¸€è½®ç»ƒä¹ ã€‚",
)

clr_btn = w_btn_cols[1].button(
    "æ¸…é™¤[:wastebasket:]", key="writing-clear", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ¸…é™¤å†™ä½œç»ƒä¹ å†…å®¹ã€‚"
)

wrd_btn = w_btn_cols[2].button(
    "å•è¯[:abc:]", key="word", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ£€æŸ¥å•è¯æ‹¼å†™é”™è¯¯ã€‚"
)

grm_btn = w_btn_cols[3].button(
    "è¯­æ³•[:triangular_ruler:]", key="grammar", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ£€æŸ¥è¯­æ³•é”™è¯¯ã€‚"
)

lgc_btn = w_btn_cols[4].button(
    "é€»è¾‘[:brain:]", key="logic", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ”¹å–„æ–‡ç« ç»“æ„å’Œé€»è¾‘ã€‚"
)

plh_btn = w_btn_cols[5].button(
    "æ¶¦è‰²[:art:]", key="polish", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæé«˜è¯æ±‡é‡å’Œå¥å¼å¤šæ ·æ€§ã€‚"
)

rvn_btn = w_btn_cols[6].button(
    "ä¿®æ­£[:wrench:]", key="revision", help="âœ¨ ç‚¹å‡»æŒ‰é’®ï¼Œæ¥å—AIä¿®æ­£å»ºè®®ã€‚"
)

if rfh_btn:
    on_project_changed("å†™ä½œç»ƒä¹ -åˆ·æ–°")
    suggestions.empty()
    ai_tip_container.empty()
    initialize_writing_chat()
    st.rerun()

if clr_btn:
    pass

if grm_btn:
    on_project_changed("å†™ä½œç»ƒä¹ -è¯­æ³•")
    suggestions.empty()
    result = check_grammar(st.session_state["writing-text"])
    html = display_grammar_errors(result)
    suggestions.markdown(html + TIPPY_JS, unsafe_allow_html=True)
    update_sidebar_status(sidebar_status)

if wrd_btn:
    on_project_changed("å†™ä½œç»ƒä¹ -å•è¯")
    suggestions.empty()
    result = check_spelling(st.session_state["writing-text"])
    html = display_word_spell_errors(result)
    suggestions.markdown(html + TIPPY_JS, unsafe_allow_html=True)

if plh_btn:
    on_project_changed("å†™ä½œç»ƒä¹ -æ¶¦è‰²")
    suggestions.empty()
    result = polish_article(st.session_state["writing-text"])

    if not result:
        suggestions.write("æ–‡å­—è¡¨è¿°å¾ˆå®Œç¾ï¼Œæˆ‘æ— éœ€è¿›è¡Œä»»ä½•æ¶¦è‰²ã€‚ğŸ‘ğŸ‘ğŸ‘")
    else:
        suggestions.markdown("å»ºè®®æ–‡ç¨¿ï¼š")
        suggestions.markdown(result["corrected"], unsafe_allow_html=True)
        suggestions.divider()
        suggestions.write("è§£é‡Šï¼š")
        suggestions.write(result["explanation"])

if lgc_btn:
    on_project_changed("å†™ä½œç»ƒä¹ -é€»è¾‘")
    suggestions.empty()
    result = logic_article(st.session_state["writing-text"])
    if not result:
        suggestions.write("å¾ˆå¥½ï¼Œæ–‡ç« çš„ç»“æ„å’Œé€»è¾‘å·²ç»å¾ˆå®Œå–„äº†ã€‚ğŸ‘ğŸ‘ğŸ‘")
    else:
        suggestions.markdown("å»ºè®®æ–‡ç¨¿ï¼š")
        if result["corrected"]:
            suggestions.markdown(result["corrected"], unsafe_allow_html=True)
            suggestions.divider()
        suggestions.write("è§£é‡Šï¼š")
        suggestions.write(result["explanation"])

if rvn_btn:
    on_project_changed("å†™ä½œç»ƒä¹ -ä¿®æ­£")
    result = check_grammar(st.session_state["writing-text"])
    if result["error_type"] == "LanguageError":
        content = remove_markup(result["corrected"])
        st.session_state["writing-content"] = content
        st.rerun()


# endregion
